{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show and Tell: A Neural Image Caption Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "import string\n",
    "import pickle\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join, isdir, isfile, exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1000268201_693b08cb0e.jpg', '1001773457_577c3a7d70.jpg', '1002674143_1b742ab4b8.jpg', '1003163366_44323f5815.jpg', '1007129816_e794419615.jpg']\n"
     ]
    }
   ],
   "source": [
    "meta_info = {\n",
    "    'image_dir': 'Flicker8k_Dataset/',\n",
    "    'train_list': 'Flickr8k_text/Flickr_8k.trainImages.txt',\n",
    "    'dev_list': 'Flickr8k_text/Flickr_8k.devImages.txt',\n",
    "    'test_list': 'Flickr8k_text/Flickr_8k.testImages.txt',\n",
    "    'text_dir': 'Flickr8k_text/'\n",
    "}\n",
    "\n",
    "print(listdir(meta_info['image_dir'])[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" feature extract CNN model\n",
    "This paper used GoogLeNet (InceptionV1) which got good grades in ImageNet 2014\n",
    "but for convenience of implementation, I used various models including InceptionV3 in built-in module of keras.\n",
    "My model has the best performance at VGG19.\n",
    "\"\"\"\n",
    "def model_select(model_name):\n",
    "    if model_name == 'VGG16':\n",
    "        from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "        model = VGG16() # 4096\n",
    "    elif model_name == 'VGG19':\n",
    "        from keras.applications.vgg19 import VGG19, preprocess_input \n",
    "        model = VGG19() # 4096\n",
    "    elif model_name == 'ResNet50':\n",
    "        from keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "        model = ResNet50() # 4096\n",
    "    elif model_name == 'InceptionV3':\n",
    "        from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "        model = InceptionV3() # 2048,\n",
    "    elif model_name == 'InceptionResNetV2':\n",
    "        from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "        model = InceptionResNetV2() # 1536,\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 139,570,240\n",
      "Trainable params: 139,570,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_name = 'VGG19'\n",
    "base_model = model_select(model_name)\n",
    "# using FC2 layer output\n",
    "cnn_model = Model(inputs=base_model.inputs, outputs=base_model.layers[-2].output)\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image to feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Usually training set is the bigger,\n",
    "so I prefer to testing with validation set first.\n",
    "\"\"\"\n",
    "\n",
    "dev_features = {}\n",
    "dev_h5 = 'dev_features.h5'\n",
    "with h5py.File(dev_h5, 'w') as h5f:\n",
    "    with open(meta_info['dev_list']) as f:\n",
    "        c = 0 # count\n",
    "        contents = f.read()\n",
    "        for line in contents.split('\\n'):\n",
    "            if line == '': # last line or error line\n",
    "                print(c)\n",
    "                continue\n",
    "            if c % 100 == 0:\n",
    "                print(c)\n",
    "            # Unlike other models, inception models use the larger image sizes.\n",
    "            if model_name.find('Inception') != -1:\n",
    "                target_size = (299, 299)\n",
    "            else:\n",
    "                target_size = (224, 224)\n",
    "                \n",
    "            img_path = line\n",
    "            img = load_img(meta_info['image_dir'] + img_path, target_size=target_size)\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            img = preprocess_input(img)\n",
    "            feature = cnn_model.predict(img)\n",
    "            h5f.create_dataset(img_path.split('.')[0], data=feature)\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.        0.        1.0180278 ... 0.        0.        0.       ]]\n",
      "(1, 4096)\n"
     ]
    }
   ],
   "source": [
    "# feature test\n",
    "with h5py.File('dev_features.h5', 'r') as h5f:\n",
    "    print(h5f['2090545563_a4e66ec76b'][:])\n",
    "    print(h5f['2090545563_a4e66ec76b'][:].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n"
     ]
    }
   ],
   "source": [
    "train_features = {}\n",
    "train_h5 = 'train_features.h5'\n",
    "with h5py.File(train_h5, 'w') as h5f:\n",
    "    with open(meta_info['train_list']) as f:\n",
    "        c = 0 # count\n",
    "        contents = f.read()\n",
    "        for line in contents.split('\\n'):\n",
    "            if line == '': # last line or error line\n",
    "                print(c)\n",
    "                continue\n",
    "            if c % 1000 == 0:\n",
    "                print(c)\n",
    "\n",
    "            if model_name.find('Inception') != -1:\n",
    "                target_size = (299, 299)\n",
    "            else:\n",
    "                target_size = (224, 224)\n",
    "                \n",
    "            img_path = line\n",
    "            img = load_img(meta_info['image_dir'] + img_path, target_size=target_size)\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            img = preprocess_input(img)\n",
    "            feature = cnn_model.predict(img)\n",
    "            h5f.create_dataset(img_path.split('.')[0], data=feature)\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "test_features = {}\n",
    "test_h5 = 'test_features.h5'\n",
    "with h5py.File(test_h5, 'w') as h5f:\n",
    "    with open(meta_info['test_list']) as f:\n",
    "        c = 0 # count\n",
    "        contents = f.read()\n",
    "        for line in contents.split('\\n'):\n",
    "            if line == '': # last line or error line\n",
    "                print(c)\n",
    "                continue\n",
    "            if c % 100 == 0:\n",
    "                print(c)\n",
    "\n",
    "            if model_name.find('Inception') != -1:\n",
    "                target_size = (299, 299)\n",
    "            else:\n",
    "                target_size = (224, 224)\n",
    "                \n",
    "            img_path = line\n",
    "            img = load_img(meta_info['image_dir'] + img_path, target_size=target_size)\n",
    "            img = img_to_array(img)\n",
    "            img = img.reshape((1, img.shape[0], img.shape[1], img.shape[2]))\n",
    "            img = preprocess_input(img)\n",
    "            feature = cnn_model.predict(img)\n",
    "            h5f.create_dataset(img_path.split('.')[0], data=feature)\n",
    "            c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "40460\n",
      "number of images: 8092\n",
      "number of catpions: 40460\n",
      "number of words: 9068\n"
     ]
    }
   ],
   "source": [
    "\"\"\" full captions to dictionary\n",
    "The dictionary has full dataset(training, validation, and test captions), \n",
    "and numbers are eliminated from all captions.\n",
    "Removing numbers improves performance (by about 3 points for bleu-1)\n",
    "\"\"\"\n",
    "\n",
    "captions = dict()\n",
    "words = set()\n",
    "\n",
    "with open(join(meta_info['text_dir'], 'Flickr8k.token.txt')) as f:\n",
    "    contents = f.read()\n",
    "    n_captions = 0\n",
    "    for line in contents.split('\\n'):\n",
    "        if line == '':\n",
    "            print(n_captions)\n",
    "            continue\n",
    "        if n_captions % 10000 == 0:\n",
    "            print(n_captions)\n",
    "        \n",
    "        file, caption = line.split('\\t')\n",
    "        \n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        \n",
    "        caption2 = []\n",
    "        for word in caption.split():\n",
    "            # remove number\n",
    "            if word.isalpha():\n",
    "                caption2.append(word.translate(table))\n",
    "        caption = ' '.join(caption2)\n",
    "        \n",
    "        img_id = file.split('.')[0]\n",
    "        \n",
    "        if img_id in captions.keys():\n",
    "            captions[img_id].append(caption)\n",
    "        else:\n",
    "            captions[img_id] = [caption]\n",
    "        n_captions += 1\n",
    "\n",
    "        [words.add(word) for word in caption.split()]\n",
    "        \n",
    "print('number of images: %d' % len(captions))\n",
    "print('number of catpions: %d' % n_captions)\n",
    "print('number of words: %d' % len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A black dog is running after a white dog in the snow', 'Black dog chasing brown dog through snow', 'Two dogs chase each other across the snowy ground', 'Two dogs play together in the snow', 'Two dogs running through a low lying body of water']\n",
      "['the boy laying face down on a skateboard is being pushed along the ground by another boy', 'Two girls play on a skateboard in a courtyard', 'Two people play on a long skateboard', 'Two small children in red shirts playing on a skateboard', 'two young children on a skateboard going across a sidewalk']\n",
      "['The dogs are in the snow in front of a fence', 'The dogs play on the snow', 'Two brown dogs playfully fight in the snow', 'Two brown dogs wrestle in the snow', 'Two dogs playing in the snow']\n"
     ]
    }
   ],
   "source": [
    "# train set caption test\n",
    "print(captions['2513260012_03d33305cf'])\n",
    "# dev set caption test\n",
    "print(captions['2090545563_a4e66ec76b'])\n",
    "# test set caption test\n",
    "print(captions['3385593926_d3e9c21170'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "number of catpions: 1000\n",
      "number of catpions: 5000\n",
      "number of words: 3409\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Only dev captions are taken from the full captions set.\n",
    "Unlike above caption, this captions has sign of start and end for sequence.\n",
    "Each [CLS], [SEP], based BERT\n",
    "keras' tokenizer removes <>, so need to further processing in this process.\n",
    "\"\"\"\n",
    "\n",
    "dev_captions = dict()\n",
    "dev_words = set()\n",
    "\n",
    "with open(join(meta_info['text_dir'], 'Flickr_8k.devImages.txt')) as f:\n",
    "    contents = f.read()\n",
    "    n_dev_captions = 0\n",
    "    for line in contents.split('\\n'):\n",
    "        if line == '':\n",
    "            print(n_dev_captions)\n",
    "            continue\n",
    "        if n_dev_captions % 10000 == 0:\n",
    "            print(n_dev_captions)\n",
    "        \n",
    "        file = line.split('.')[0]\n",
    "        \n",
    "        for caption in captions[file]:\n",
    "            # start sign: [CLS]\n",
    "            # end sign: [SEP]\n",
    "            caption = '[CLS] ' + caption + ' [SEP]'\n",
    "            caption = caption.replace('\\n', '')\n",
    "            \n",
    "            if file in dev_captions.keys():\n",
    "                dev_captions[file].append(caption)\n",
    "            else:\n",
    "                dev_captions[file] = [caption]\n",
    "            n_dev_captions += 1\n",
    "            \n",
    "            [dev_words.add(word) for word in caption.split()]\n",
    "\n",
    "print('number of catpions: %d' % len(dev_captions))\n",
    "print('number of catpions: %d' % n_dev_captions)\n",
    "print('number of words: %d' % len(dev_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sssss the boy laying face down on a skateboard is being pushed along the ground by another boy eeeee', 'sssss Two girls play on a skateboard in a courtyard eeeee', 'sssss Two people play on a long skateboard eeeee', 'sssss Two small children in red shirts playing on a skateboard eeeee', 'sssss two young children on a skateboard going across a sidewalk eeeee']\n"
     ]
    }
   ],
   "source": [
    "# dev set caption test\n",
    "print(dev_captions['2090545563_a4e66ec76b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "number of catpions: 6000\n",
      "number of catpions: 30000\n",
      "number of words: 7816\n",
      "max number of words in single sentence: 36\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Unlike a dev set, training set must count the maximum number of words in single sentence.\n",
    "Variable M do that role.\n",
    "\"\"\"\n",
    "\n",
    "train_captions = dict()\n",
    "train_words = set()\n",
    "\n",
    "M = 0 # max length in single sentence\n",
    "\n",
    "with open(join(meta_info['text_dir'], 'Flickr_8k.trainImages.txt')) as f:\n",
    "    contents = f.read()\n",
    "    n_train_captions = 0\n",
    "    for line in contents.split('\\n'):\n",
    "        if line == '':\n",
    "            print(n_train_captions)\n",
    "            continue\n",
    "        if n_train_captions % 10000 == 0:\n",
    "            print(n_train_captions)\n",
    "        \n",
    "        file = line.split('.')[0]\n",
    "        \n",
    "        for caption in captions[file]:\n",
    "            caption = '[CLS] ' + caption + ' [SEP]'\n",
    "            caption = caption.replace('\\n', '')\n",
    "            \n",
    "            if file in train_captions.keys():\n",
    "                train_captions[file].append(caption)\n",
    "            else:\n",
    "                train_captions[file] = [caption]\n",
    "            n_train_captions += 1\n",
    "            \n",
    "            t = caption.split()\n",
    "            if len(t) > M:\n",
    "                M = len(t)\n",
    "            [train_words.add(word) for word in t]\n",
    "\n",
    "# n_vocabs = len(train_words) # all word, based str.split()\n",
    "\n",
    "print('number of catpions: %d' % len(train_captions))\n",
    "print('number of catpions: %d' % n_train_captions)\n",
    "print('number of words: %d' % len(train_words))\n",
    "\n",
    "# print('vocabulary size: %d' % n_vocabs)\n",
    "print('max number of words in single sentence: %d' % M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sssss A black dog is running after a white dog in the snow eeeee', 'sssss Black dog chasing brown dog through snow eeeee', 'sssss Two dogs chase each other across the snowy ground eeeee', 'sssss Two dogs play together in the snow eeeee', 'sssss Two dogs running through a low lying body of water eeeee']\n"
     ]
    }
   ],
   "source": [
    "# train set caption test\n",
    "print(train_captions['2513260012_03d33305cf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "number of catpions: 1000\n",
      "number of catpions: 5000\n",
      "number of words: 3266\n"
     ]
    }
   ],
   "source": [
    "test_captions = dict()\n",
    "test_words = set()\n",
    "\n",
    "with open(join(meta_info['text_dir'], 'Flickr_8k.testImages.txt')) as f:\n",
    "    contents = f.read()\n",
    "    n_test_captions = 0\n",
    "    for line in contents.split('\\n'):\n",
    "        if line == '':\n",
    "            print(n_test_captions)\n",
    "            continue\n",
    "        if n_test_captions % 10000 == 0:\n",
    "            print(n_test_captions)\n",
    "        \n",
    "        file = line.split('.')[0]\n",
    "        \n",
    "        for caption in captions[file]:\n",
    "            caption = '[CLS] ' + caption + ' [SEP]'\n",
    "            caption = caption.replace('\\n', '')\n",
    "            \n",
    "            if file in test_captions.keys():\n",
    "                test_captions[file].append(caption)\n",
    "            else:\n",
    "                test_captions[file] = [caption]\n",
    "            n_test_captions += 1\n",
    "            \n",
    "            [test_words.add(word) for word in caption.split()]\n",
    "\n",
    "print('number of catpions: %d' % len(test_captions))\n",
    "print('number of catpions: %d' % n_test_captions)\n",
    "print('number of words: %d' % len(test_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sssss The dogs are in the snow in front of a fence eeeee', 'sssss The dogs play on the snow eeeee', 'sssss Two brown dogs playfully fight in the snow eeeee', 'sssss Two brown dogs wrestle in the snow eeeee', 'sssss Two dogs playing in the snow eeeee']\n"
     ]
    }
   ],
   "source": [
    "# test set caption test\n",
    "print(test_captions['3385593926_d3e9c21170'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" make tokenizer using keras.\n",
    "Making tokenizer, only use train captions.\n",
    "\"\"\"\n",
    "def make_tokenizer(captions):\n",
    "    texts = []\n",
    "    for _, caption_list in captions.items():\n",
    "        for caption in caption_list:\n",
    "            texts.append(caption)\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of vocabulary: 7277\n"
     ]
    }
   ],
   "source": [
    "tokenizer = make_tokenizer(train_captions)\n",
    "n_vocabs = len(tokenizer.word_index) + 1 # because index 0, plus 1\n",
    "print('number of vocabulary: %d' % n_vocabs)\n",
    "# print(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pkl', 'rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "# print(len(tokenizer.word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100000\n",
      "200000\n",
      "300000\n",
      "352425\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Make sequence, Make next word based ground truth.\n",
    "If single sentence consisting of N words, N + 1(because nd sign) sequences are created.\n",
    "Ex) Hi, I am a boy.\n",
    "sequence                 -> next word\n",
    "[]   []   []   []   [Hi] -> I\n",
    "[]   []   []   [Hi] [I]  -> am\n",
    "[]   []   [Hi] [I]  [am] -> a\n",
    "...\n",
    "[Hi] [I] [am] [a] [boy] -> '[SEP]' (end sign)\n",
    "\"\"\"\n",
    "train_sequences = list()\n",
    "train_next_word = list()\n",
    "\n",
    "c = 0\n",
    "train_sequences_h5 = 'train_sequences.h5'\n",
    "train_next_word_h5 = 'train_next_word.h5'\n",
    "h5f1 = h5py.File(train_sequences_h5, 'w')\n",
    "h5f2 = h5py.File(train_next_word_h5, 'w')\n",
    "for img_id, captions in train_captions.items():\n",
    "#     print(img_id)\n",
    "    Xtrain = list()\n",
    "    ytrain = list()\n",
    "    for caption in captions:\n",
    "        sequence = tokenizer.texts_to_sequences([caption])[0]\n",
    "        \n",
    "        for i in range(1, len(sequence)): # except start sign\n",
    "            if c % 100000 == 0:\n",
    "                print(c)\n",
    "            train_sequences.append(pad_sequences([sequence[:i]], M)[0])\n",
    "            Xtrain.append(pad_sequences([sequence[:i]], M)[0])\n",
    "            train_next_word.append(to_categorical([sequence[i]], num_classes=n_vocabs)[0])\n",
    "            ytrain.append(to_categorical([sequence[i]], num_classes=n_vocabs)[0])\n",
    "            c += 1\n",
    "    h5f1.create_dataset(img_id, data=Xtrain)\n",
    "    h5f2.create_dataset(img_id, data=ytrain)\n",
    "h5f1.close()\n",
    "h5f2.close()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2]\n",
      "[0. 1. 0. ... 0. 0. 0.]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# test sequences and next word\n",
    "print(train_sequences[0])\n",
    "print(train_next_word[0])\n",
    "print(train_sequences[1])\n",
    "print(train_next_word[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "58661\n"
     ]
    }
   ],
   "source": [
    "dev_sequences = list()\n",
    "dev_next_word = list()\n",
    "\n",
    "c = 0\n",
    "dev_sequences_h5 = 'dev_sequences.h5'\n",
    "dev_next_word_h5 = 'dev_next_word.h5'\n",
    "h5f1 = h5py.File(dev_sequences_h5, 'w')\n",
    "h5f2 = h5py.File(dev_next_word_h5, 'w')\n",
    "for img_id, captions in dev_captions.items():\n",
    "#     print(img_id)\n",
    "    Xdev = list()\n",
    "    ydev = list()\n",
    "    for caption in captions:\n",
    "        text = tokenizer.texts_to_sequences([caption])[0]\n",
    "        \n",
    "        for i in range(1, len(text)):\n",
    "            if c % 10000 == 0:\n",
    "                print(c)\n",
    "            dev_sequences.append(pad_sequences([text[:i]], M)[0])\n",
    "            Xdev.append(pad_sequences([text[:i]], M)[0])\n",
    "            dev_next_word.append(to_categorical([text[i]], num_classes=n_vocabs)[0])\n",
    "            ydev.append(to_categorical([text[i]], num_classes=n_vocabs)[0])\n",
    "            c += 1\n",
    "    h5f1.create_dataset(img_id, data=Xdev)\n",
    "    h5f2.create_dataset(img_id, data=ydev)\n",
    "h5f1.close()\n",
    "h5f2.close()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "58389\n"
     ]
    }
   ],
   "source": [
    "test_sequences = list()\n",
    "test_next_word = list()\n",
    "\n",
    "c = 0\n",
    "test_sequences_h5 = 'test_sequences.h5'\n",
    "test_next_word_h5 = 'test_next_word.h5'\n",
    "h5f1 = h5py.File(test_sequences_h5, 'w')\n",
    "h5f2 = h5py.File(test_next_word_h5, 'w')\n",
    "for img_id, captions in test_captions.items():\n",
    "#     print(img_id)\n",
    "    Xtest = list()\n",
    "    ytest = list()\n",
    "    for caption in captions:\n",
    "        text = tokenizer.texts_to_sequences([caption])[0]\n",
    "        \n",
    "        for i in range(1, len(text)):\n",
    "            if c % 10000 == 0:\n",
    "                print(c)\n",
    "            test_sequences.append(pad_sequences([text[:i]], M)[0])\n",
    "            Xtest.append(pad_sequences([text[:i]], M)[0])\n",
    "            test_next_word.append(to_categorical([text[i]], num_classes=n_vocabs)[0])\n",
    "            ytest.append(to_categorical([text[i]], num_classes=n_vocabs)[0])\n",
    "            c += 1\n",
    "    h5f1.create_dataset(img_id, data=Xtest)\n",
    "    h5f2.create_dataset(img_id, data=ytest)\n",
    "h5f1.close()\n",
    "h5f2.close()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data processing end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bellow code isn't need to look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# h5 -> Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = list()\n",
    "train_next_word = list()\n",
    "\n",
    "c = 0\n",
    "train_sequences_pkl = 'train_sequences.pkl'\n",
    "train_next_word_pkl = 'train_next_word.pkl'\n",
    "\n",
    "X = dict()\n",
    "Y = dict()\n",
    "\n",
    "for img_id, captions in train_captions.items():\n",
    "#     print(img_id)\n",
    "    Xtrain = list()\n",
    "    ytrain = list()\n",
    "    for caption in captions:\n",
    "        text = tokenizer.texts_to_sequences([caption])[0]\n",
    "        \n",
    "        for i in range(1, len(text)):\n",
    "            if c % 100000 == 0:\n",
    "                print(c)\n",
    "            train_sequences.append(pad_sequences([text[:i]], M)[0])\n",
    "            Xtrain.append(pad_sequences([text[:i]], M)[0])\n",
    "            train_next_word.append(to_categorical([text[i]], num_classes=n_vocabs)[0])\n",
    "            ytrain.append(to_categorical([text[i]], num_classes=n_vocabs)[0])\n",
    "            c += 1\n",
    "    X[img_id] = Xtrain\n",
    "    Y[img_id] = ytrain\n",
    "with open(train_sequences_pkl, 'wb') as f:\n",
    "    pickle.dump(X, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open(train_next_word_pkl, 'wb') as f:\n",
    "    pickle.dump(Y, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(train_sequences_pkl, 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    print(test['2513260012_03d33305cf'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8256\n",
      "8256\n"
     ]
    }
   ],
   "source": [
    "train_id_word = dict()\n",
    "\n",
    "for i, word in enumerate(train_words):\n",
    "    train_id_word[i] = word\n",
    "    train_word_id[word] = i\n",
    "\n",
    "print(len(train_id_word))\n",
    "print(len(train_word_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3523\n",
      "3523\n"
     ]
    }
   ],
   "source": [
    "dev_id_word = dict()\n",
    "dev_word_id = dict()\n",
    "\n",
    "for i, word in enumerate(dev_words):\n",
    "    dev_id_word[i] = word\n",
    "    dev_word_id[word] = i\n",
    "\n",
    "print(len(dev_id_word))\n",
    "print(len(dev_word_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "nextwords = list()\n",
    "\n",
    "data = {}\n",
    "for captions in train_captions.items():\n",
    "#     print(captions)\n",
    "    data[captions[0]] = []\n",
    "    for caption in captions[1]:\n",
    "        t = []\n",
    "        for word in caption.split():\n",
    "            t.append(train_word_id[word])\n",
    "        data[captions[0]].append(t)\n",
    "#     print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "383454\n"
     ]
    }
   ],
   "source": [
    "id_seq = {}\n",
    "id_y = {}\n",
    "c = 0\n",
    "for key, value in data.items():\n",
    "    sub_seqs = []\n",
    "    Y = []\n",
    "    for seq in value:\n",
    "        for i in range(1, len(seq)):\n",
    "            if c % 100000 == 0:\n",
    "                print(c)\n",
    "            sub_seqs.append(sequence.pad_sequences([seq[:i]], max_length)[0])\n",
    "            y = to_categorical([seq[i]], num_classes=n_vocab + 1)\n",
    "            Y.append(y[0])\n",
    "            c += 1\n",
    "            \n",
    "    id_seq[key] = sub_seqs\n",
    "    id_y[key] = Y\n",
    "print(c)\n",
    "#         print(id_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file_path = 'train_id_seq.h5'\n",
    "with h5py.File(h5file_path, 'w') as h5f:\n",
    "    for key, value in id_seq.items():\n",
    "        h5f.create_dataset(key, data=value)\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8133    0    0 ...    0    0    0]\n",
      " [8133 4381    0 ...    0    0    0]\n",
      " [8133 4381  850 ...    0    0    0]\n",
      " ...\n",
      " [8133 4752 3548 ...    0    0    0]\n",
      " [8133 4752 3548 ...    0    0    0]\n",
      " [8133 4752 3548 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "h5file_path = 'train_id_seq.h5'\n",
    "with h5py.File(h5file_path, 'r') as h5f:\n",
    "    print(h5f['667626_18933d713e'][:])\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file_path = 'train_id_y.h5'\n",
    "with h5py.File(h5file_path, 'w') as h5f:\n",
    "    for key, value in id_y.items():\n",
    "        h5f.create_dataset(key, data=value)\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "h5file_path = 'train_id_y.h5'\n",
    "with h5py.File(h5file_path, 'r') as h5f:\n",
    "    print(h5f['667626_18933d713e'][:])\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "sequences = list()\n",
    "nextwords = list()\n",
    "\n",
    "data = {}\n",
    "for captions in dev_captions.items():\n",
    "#     print(captions)\n",
    "    data[captions[0]] = []\n",
    "    for caption in captions[1]:\n",
    "        t = []\n",
    "        for word in caption.split():\n",
    "            t.append(dev_word_id[word])\n",
    "        data[captions[0]].append(t)\n",
    "#     print(data)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "64445\n"
     ]
    }
   ],
   "source": [
    "id_seq = {}\n",
    "id_y = {}\n",
    "c = 0\n",
    "for key, value in data.items():\n",
    "    sub_seqs = []\n",
    "    Y = []\n",
    "    for seq in value:\n",
    "        for i in range(1, len(seq)):\n",
    "            if c % 10000 == 0:\n",
    "                print(c)\n",
    "            sub_seqs.append(sequence.pad_sequences([seq[:i]], max_length, padding='post')[0])\n",
    "            y = to_categorical([seq[i]], num_classes=n_vocab)\n",
    "            Y.append(y[0])\n",
    "            c += 1\n",
    "    id_seq[key] = sub_seqs\n",
    "    id_y[key] = Y\n",
    "print(c)\n",
    "#         print(id_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file_path = 'dev_id_seq.h5'\n",
    "with h5py.File(h5file_path, 'w') as h5f:\n",
    "    for key, value in id_seq.items():\n",
    "        h5f.create_dataset(key, data=value)\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1626    0    0 ...    0    0    0]\n",
      " [1626 1622    0 ...    0    0    0]\n",
      " [1626 1622  830 ...    0    0    0]\n",
      " ...\n",
      " [1626 3127 2829 ...    0    0    0]\n",
      " [1626 3127 2829 ...    0    0    0]\n",
      " [1626 3127 2829 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "h5file_path = 'dev_id_seq.h5'\n",
    "with h5py.File(h5file_path, 'r') as h5f:\n",
    "    print(h5f['2090545563_a4e66ec76b'][:])\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file_path = 'dev_id_y.h5'\n",
    "with h5py.File(h5file_path, 'w') as h5f:\n",
    "    for key, value in id_y.items():\n",
    "        h5f.create_dataset(key, data=value)\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "h5file_path = 'dev_id_y.h5'\n",
    "with h5py.File(h5file_path, 'r') as h5f:\n",
    "    print(h5f['2090545563_a4e66ec76b'][:])\n",
    "# print(feature_np)\n",
    "# np.squeeze(feature_np)\n",
    "# print(feature_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
